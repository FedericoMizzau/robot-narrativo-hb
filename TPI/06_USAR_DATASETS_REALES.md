# üìö SISTEMA PARA USAR DATASETS REALES - COMPLETADO

## ‚úÖ Lo que se ha Implementado

### 1. Procesador de Datasets (`procesar_dataset.py`)
- ‚úÖ Soporta m√∫ltiples formatos: TXT, JSON
- ‚úÖ Procesa archivos individuales o directorios completos
- ‚úÖ Limpia y normaliza el texto autom√°ticamente
- ‚úÖ Valida que los cuentos sean adecuados (50-2000 palabras)
- ‚úÖ Guarda en formato optimizado para entrenamiento

### 2. Script de Fine-Tuning Mejorado (`fine_tuning.py`)
- ‚úÖ Interfaz de l√≠nea de comandos f√°cil de usar
- ‚úÖ Detecci√≥n autom√°tica de GPU/CPU
- ‚úÖ Par√°metros configurables (√©pocas, batch size, etc.)
- ‚úÖ Manejo de errores y checkpoints
- ‚úÖ Optimizado para diferentes hardware

### 3. Descargador de Datasets (`descargar_dataset_ejemplo.py`)
- ‚úÖ Ejemplo para descargar desde Hugging Face
- ‚úÖ F√°cil de adaptar a otros datasets

### 4. Gu√≠a Completa (`GUIA_DATASETS.md`)
- ‚úÖ D√≥nde conseguir datasets
- ‚úÖ C√≥mo procesarlos
- ‚úÖ C√≥mo entrenar
- ‚úÖ C√≥mo usar el modelo entrenado

### 5. Integraci√≥n con Sistema Actual
- ‚úÖ `generador_ml.py` actualizado para usar modelos fine-tuneados
- ‚úÖ Soporta rutas a modelos propios
- ‚úÖ Fallback autom√°tico si el modelo no est√° disponible

---

## üöÄ Flujo Completo de Uso

### Paso 1: Conseguir Dataset
```bash
# Opci√≥n A: Desde Hugging Face (requiere: pip install datasets)
python descargar_dataset_ejemplo.py

# Opci√≥n B: Usar archivo propio
# Simplemente coloca tu archivo de cuentos en el proyecto
```

### Paso 2: Procesar Dataset
```bash
source venv/Scripts/activate

# Procesar archivo
python procesar_dataset.py mi_dataset.txt

# O procesar directorio
python procesar_dataset.py ./mis_cuentos/ txt
```

**Resultado:** `data/cuentos_procesados.txt` listo para entrenar

### Paso 3: Entrenar Modelo
```bash
# Entrenamiento b√°sico
python fine_tuning.py data/cuentos_procesados.txt

# Con opciones
python fine_tuning.py data/cuentos_procesados.txt \
    --epochs 5 \
    --batch 2 \
    --output ./mi_modelo
```

**Resultado:** Modelo entrenado en `./modelo_cuentos` (o directorio especificado)

### Paso 4: Usar Modelo Entrenado
```python
# En app.py, cambiar:
generador = GeneradorCuento(
    usar_ml=True,
    modelo_ml="./modelo_cuentos"  # Ruta a tu modelo
)
```

---

## üìä Requisitos y Tiempos

### Dataset M√≠nimo:
- **50-100 cuentos** para empezar
- **200-500 cuentos** para mejor calidad
- **1000+ cuentos** para resultados √≥ptimos

### Tiempos Estimados de Entrenamiento:

| Hardware | 100 cuentos | 500 cuentos | 1000 cuentos |
|----------|-------------|-------------|--------------|
| **GPU NVIDIA** | 10-20 min | 30-60 min | 1-2 horas |
| **CPU** | 2-4 horas | 8-12 horas | 16-24 horas |

### Memoria Requerida:
- **GPU:** 4-8 GB VRAM
- **CPU:** 8-16 GB RAM
- **Disco:** ~2-5 GB (modelo + dataset)

---

## üéØ D√≥nde Conseguir Datasets

### 1. Hugging Face (Recomendado)
- URL: https://huggingface.co/datasets
- Buscar: "spanish stories", "cuentos", "fairy tales"
- Instalar: `pip install datasets`

### 2. Proyecto Gutenberg
- URL: https://www.gutenberg.org/
- Libros y cuentos en dominio p√∫blico
- Muchos en espa√±ol

### 3. Kaggle
- URL: https://www.kaggle.com/datasets
- Buscar: "spanish stories", "cuentos"

### 4. Recopilar Propios
- Wikipedia (art√≠culos sobre cuentos)
- Bibliotecas digitales
- Crear propios

---

## üìù Ejemplo R√°pido

```bash
# 1. Procesar tu dataset
python procesar_dataset.py mis_cuentos.txt

# 2. Entrenar (con GPU si est√° disponible)
python fine_tuning.py data/cuentos_procesados.txt --epochs 3

# 3. El modelo se guarda en ./modelo_cuentos

# 4. Actualizar app.py:
#    modelo_ml="./modelo_cuentos"

# 5. Probar
python app.py
```

---

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Ajustar Par√°metros de Entrenamiento:

```bash
# M√°s √©pocas (mejor calidad, m√°s tiempo)
python fine_tuning.py data/cuentos_procesados.txt --epochs 5

# Batch m√°s peque√±o (si hay problemas de memoria)
python fine_tuning.py data/cuentos_procesados.txt --batch 1

# Modelo base diferente
python fine_tuning.py data/cuentos_procesados.txt --model distilgpt2

# Forzar CPU
python fine_tuning.py data/cuentos_procesados.txt --cpu
```

---

## üîç Verificar Calidad

### Antes de Entrenar:
```python
from procesar_dataset import ProcesadorDataset

procesador = ProcesadorDataset()
cuentos = procesador.procesar_archivo_txt("data/cuentos_procesados.txt")

print(f"Total: {len(cuentos)} cuentos")
print(f"Promedio: {sum(len(c.split()) for c in cuentos) / len(cuentos):.0f} palabras")
```

### Despu√©s de Entrenar:
```python
from generador_ml import GeneradorML

gen = GeneradorML(modelo="./modelo_cuentos")
cuento = gen.generar_cuento("Un cuento sobre...")
print(cuento)
```

---

## üìÅ Archivos Creados

- ‚úÖ `procesar_dataset.py` - Procesador de datasets
- ‚úÖ `fine_tuning.py` - Script de fine-tuning mejorado
- ‚úÖ `descargar_dataset_ejemplo.py` - Ejemplo para Hugging Face
- ‚úÖ `GUIA_DATASETS.md` - Gu√≠a completa
- ‚úÖ `06_USAR_DATASETS_REALES.md` - Este resumen

---

## ‚úÖ Estado Actual

- ‚úÖ **Sistema completo para usar datasets reales**
- ‚úÖ **Procesador de datasets funcionando**
- ‚úÖ **Script de fine-tuning optimizado**
- ‚úÖ **Integraci√≥n con sistema actual**
- ‚úÖ **Documentaci√≥n completa**

---

## üéì Pr√≥ximos Pasos

1. **Conseguir dataset** de cuentos en espa√±ol
2. **Procesar** con `procesar_dataset.py`
3. **Entrenar** con `fine_tuning.py`
4. **Usar** el modelo entrenado en el sistema

---

**¬°El sistema est√° listo para usar datasets reales y mejorar la calidad de los cuentos generados! üöÄ**


